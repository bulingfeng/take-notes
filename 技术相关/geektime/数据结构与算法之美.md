## 复杂度分析

### 为什么需要复杂度分析

> 有人说可以通过让代码跑一遍，然后进行统计和监控来得到结果。然后跑多次来进行结果的对比。这种方法叫做**事后统计法**。
>
> 这种方法有很严重的缺陷：
>
> > 1. 测试结果非常依赖于环境；
> > 2. 测试结果非常受数据规模的影响；

### 大O复杂度表示法

> 不运行代码的情况下，一眼能看出来代码的执行效率。

方法可以把代码运行的每一行代码的时间都认为是时间一样的，暂且当做unit_time。那么以下代码执行了多长时间呢：

```java
 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

最后的时间是(2n+2)*unit_time。

```java
 int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum = sum +  i * j;
     }
   }
 }
```

以上的代码的执行时间为：T(n) = (2n2+2n+3)*unit_time。

> 而不管是(2n+2)*unit_time还是(2n2+2n+3)*unit_time。我们都可以把其描述为f(n)的一个函数。
>
> 即大O表示O(f(n));更具体的解释为：O(2n+2)和O(2n2+2n+3)。
>
> 通常只需要考虑增长最快的因素即可，常量、系数已经变化较小的公式都可以舍去，于是上面的大O表示法可以表示为：T(n) = O(n)； T(n) = O(n2)

需要注意的是，这个大O表示法并不直接代表代码运行的时间，**它只是代表随着数据规模的变化而代码执行消耗时间的趋势**，叫做渐进时间复杂度也叫时间负责度。

快速判断时间复杂度的小技巧：

> 只关注运行代码随着数据规模增长最快的部分即可。

常见的时间复杂度案例分析

![](./image/数据结构与算法之美/1-常见的时间复杂度.png)

上面的复杂度可以分为两种：多项式量级和非多项式量级。

> 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。

### O(1)

O(1)并不是只执行了一行代码，只是常量级的时间复杂度表示方法。如下代码：

```java
 int i = 8;
 int j = 6;
 int sum = i + j;
```

> 只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

### O(logn)、O(nlogn)

```java
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

其实我们就是这个循环里面的代码执行了几次：x=log2n；

```java
 i=1;
 while (i <= n)  {
   i = i * 3;
 }
// 这段代码的时间复杂度为 O(log3n)。
```

不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。

如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了;

### O(m+n)、O(m*n)

```java
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

>m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。
>
>针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n));
>
>但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

![](./image/数据结构与算法之美/2-时间复杂度趋势变化图.png)

## 更详细的时间复杂度分析

> - 最好情况时间复杂度
> - 最坏情况时间复杂度
> - 平均情况时间复杂度
> - 均摊时间复杂度

## 数组：为什么很多编程语言的数组都是从0开始的

什么是数组？

> 数组（Array）是一种**线性表数据结构**。它用一组**连续的**内存空间，来存储一组具有**相同类型**的数据;

> a[k]_address = base_address + k * type_size
>
> a[k]_address = base_address + (k-1)*type_size
>
> 从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。
>
> 其中的k代表的是首地址。比如a[0]代表的首字母是0

## 链表

链表的分类

> 1. 单向链表；
> 2. 单向循环链表；
> 3. 双向链表；

![](./image/数据结构与算法之美/3-单向链表.png)

![](./image/数据结构与算法之美/4-单链表插入和删除.png)

![](./image/数据结构与算法之美/5-循环链表.png)

![](./image/数据结构与算法之美/6-双向链表.png)

一些误区

> 1. 既然链表的**删除**是O(1),那么单向链表和双向链表的删除效率是一样的？因为还需要进行查询，所以查询的时间是O(n),但是如果制定某个节点，那么双向链表查询就是O(1),因为它天然存储了上一个节点指针。
> 2. 链表的删除主要的时间其实都浪费在查询上了。

链表和数组的区别

> 链表是不需要连续内存的；而数组是需要连续内存的；
>
> 链表添加和删除数据消耗较小，而数组添加和删除开销严重；

LRU的实现方式

> 1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。2. 如果此数据没有在缓存链表中，又可以分为两种情况：如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。这样我们就用链表实现了一个 LRU 缓存，是不是很简单？

### 常见的链表算法

- 单链表反转 
- 链表中环的检测
- 两个有序的链表合并
- 删除链表倒数第 n 个结点
- 求链表的中间结点



### 理解指针和引用的含义

指针和引用其实含义是一样的，其实都是指的是通过这个地址能够找到这个内存中对象的存储位置；

比如链表中一些常见的一些含义：

> 1. p->next=q;表达的意思是 p的next指针存储了q节点的内存地址；
> 2. p->next=p->next->next;p节点的next节点的引用存储着p节点的下下节点内存地址；

### 警惕指针丢失和内存泄漏

下面拿单链表举例说明,比如我想在a,b节点之间插入一个x节点,假设当前的指针为p

![](./image/数据结构与算法之美/7-单链表插入.png)

常见的错误代码如下：

```
p->next=x
x->next=p->next
```

> 上面的代码其实就是一个常见的错误；
>
> > 当执行 x->next=p->next 的时候，其实由于上一行代码已经把p的下一个节点设置成x了，其实x->next就是x它自己。所以造成后面的链表都无法访问到；
>
> 解决方案1：
>
> > 先让x的下一个节点指向b，然后再让p的下一个节点指向x；也就是上面的错误代码调换下顺序。
>
> 解决方案2：
>
> > 先使用一个临时变量来存储下b节点；
> >
> > 代码编程这样了
> >
> > temp=p->next
> >
> > p->next=x
> >
> > x->next=temp
>
> **插入的时候要考虑自己是不是第一个节点**

删除节点比较简单

> p->next=p->next->next

但是要考虑是不是最后一个节点；

链表翻转的代码实现

```java
// 使用while循环
@Data
public class NewNode {

    private String data;


    private NewNode next;


    public static void main(String[] args) {
        NewNode node1 = new NewNode();
        node1.setData("node1");

        NewNode node2 = new NewNode();
        node2.setData("node2");

        NewNode node3 = new NewNode();
        node3.setData("node3");

        node1.setNext(node2);
        node2.setNext(node3);

        NewNode verseLinkList = verseLinkList(node1);

        print(verseLinkList);
    }


    public static void print(NewNode newNode){
        NewNode next=newNode;
        while (true){
            System.out.println(next.getData());
            if (next.next==null){
                return;
            }
            next=next.next;
        }
    }


    public static NewNode verseLinkList(NewNode newNode){
        NewNode pre=null;
        NewNode currentNode=newNode;
        while (true){
            if (currentNode==null){
                break;
            }
            NewNode temp=currentNode.next;
            currentNode.next=pre;
            pre=currentNode;
            currentNode=temp;
        }
        return pre;
    }
}
```


```java
// 递归
public static NewNode  reverseLinkedList(NewNode pre,NewNode newPoint){
        if (newPoint.next==null){
            newPoint.next=pre;
            return newPoint;
        }

        NewNode nextNode=newPoint.next;

        // 翻转
        newPoint.next=pre;

        return reverseLinkedList(newPoint,nextNode);
    }
```



### 两个有序链表组合成一个有序链表

> 实现要点：
>
> 1. 创建一个head头结点
> 2. 创建合并后链表的指针；创建第一个链表的指针；创建第二个链表的指针；
> 3. 移动两个有序列表的指针
> 4. 设置头结点，**移动和更新** 合并节点的指针

```java
/**
     * 1. 创建一个merge的list
     * 2. 创建两个指针，这两个指针 分别指向 两个链表 各个节点
     * 3. 进行判断和指针的异动
     * @return
     */
    public static NewNode merge(NewNode sortLinkedList1,NewNode sortLinkedList2){
        NewNode head=null;// 头节点
        NewNode mergeP=null;// 合并的指针
        NewNode p1=sortLinkedList1;
        NewNode p2=sortLinkedList2;

        while (p1!=null && p2!=null){

            NewNode temp=new NewNode();
            // 比较
            int value1=Integer.parseInt(p1.getData());
            int value2=Integer.parseInt(p2.getData());
            if (value1<value2){
                temp.setData(value1+"");
                // 移动p1指针
                p1=p1.next;
            }else if (value1>=value2){// 小于或者等于 都异动p2的指针
                temp.setData(value2+"");
                p2=p2.next;
            }

            if (head==null){
                head=temp;
                mergeP=head;
            }else {
                mergeP.next=temp;
                mergeP=temp;
            }

        }

        // 处理边界值（这个处理方式虽然能够达到效果，但是有个问题就是现在合并的链表和原来的链表使用共同的引用）
        if (p1 != null) {
            mergeP.next = p1;
        } else if (p2 != null) {
            mergeP.next = p2;
        }
        return head;
    }
```

优化的边界处理问题

```java
				// 处理边界值
        if (p1 != null) {
            while (p1 != null) {
                NewNode newNode = new NewNode();
                newNode.setData(p1.getData());
                mergeP.next = newNode;
                p1 = p1.next;
            }
        } else if (p2 != null) {
            while (p2 != null) {
                NewNode newNode = new NewNode();
                newNode.setData(p2.getData());
                mergeP.next = newNode;
                p2 = p2.next;
            }
        }
```


## Hash算法

> 任意长度的二进制字符串映射为固定长度的二进制字符串，这个映射规则就叫做hash算法。

Hash算法一般满足以下要求

> - hash值不能反向推导出来原始数据
> - 对数据敏感，哪怕修改任何一个bit的数据都会导致结果大不一样
> - 散列的冲突要小，对于不同的原始数据，hash值的冲突率要小
> - hash算法的执行效率要高，针对长文本也能够快速得到hash值

### Hash算法应用

#### 安全加密

常用于加密的算法有MD5,SHA,DES,AES

> hash算法有两个重要的特性：
>
> 1. 无法通过hash值来反推原始值
> 2. 对于不同的值冲突尽量的少
>
> 而对于`不同的值冲突尽量的少`，其实是从数学上来解释的。因为hash的值是固定的，而输出的值可以是无限的，所以理论上来说肯定是会有不同的值冲突的。只不过概率可能很小。
>
> 比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。

#### 唯一标识

>  判断视频和图片是否存在过,可以对视频或者图片做hash从而来判断这个文件是存在过。

#### 数据校验

> 比如电驴上下来一个2G的电影，但是需要分成100个块。于是这个种子上有这100个文件的hash值，当100个文件下载好之后，再进行hash，然后对比种子种的hash值是否一样，如果不一样就认为此文件被修改过，需要再次从服务器上下载。

#### 散列函数

比如HashMap的实现。而这种方式其实不关心值是否会重复，散列更关注的是是否能够均匀的分配到各个槽之中。

> 对于密码的“脱库”，其实仅仅使用SHA等加密算法还是不够的，因为有些用户的密码实在太简单，比如“0000”，“123456”之类的，如果黑客有个常用的字典表然后去强烈破解，那么就会得到相对于的密码（虽然从理论上来讲，这个破解的密码不一定是用户的密码，应为hash是有几率冲突的）
>
> 所以还需要引入一个salt来增加密码的安全性。

## 排序算法

排序算法要点

> 1. 要关心排序算法的最好复杂度，最坏复杂度和平均复杂度。
> 2. 现实工作中的数据量都比较小，比如是几百个或者1000个这个时候就需要把常量和其他系数考虑进来。
> 3. 考虑是否是原地算法，看空间的复杂度是否为O(1)。

### 冒泡排序

> 每次排序一个元素，按照最大或者最小进行排序。这里能优化的地方在于，如果有一轮没有进行位置的交换，那么则证明这个排序已经排序好了。

```java
public static void main(String[] args) {
        int[] array=new int[]{1,5,8,7,9,0};

        for (int i = 0; i < array.length-1; i++) {// 6个元素只需要比较5次即可
            for (int j = 0; j < array.length-1-i; j++) {// 实际比较的次数
                if (array[j]>array[j+1]){
                    int tem=array[j+1];
                    array[j+1]=array[j];
                    array[j]=tem;
                }
            }
        }

        Arrays.stream(array).forEach(System.out::println);
    }
```

### 插入排序

核心思路

> 一个程序或者算法最核心的就是思路，其实就是一步步该怎么做。这就需要抓住关键知识点，如果思路不清晰的时候还可以依赖图示进行辅助自己思路。
>
> 插入排序的核心思路是这样的：
>
> > 1. 把需要排序的列表分为两部分：已经排序的部分+待排序的部分。
> > 2. 数据是从后向前进行比较，然后符合条件的进行移动。

![](./image/数据结构与算法之美/8-插入排序.png)

```java
public static void insertSort(int[] array){
        /**
         * 第一个循环是指向要移动的元素
         * 第二个循环是每个元素要和之前已经排好的进行比较然后进行插入
         */
        for (int i = 1; i < array.length; i++) {
            int n1=i-1;
            int a=array[i];
            for (;n1>=0;n1--){
                int b=array[n1];
                if (a<b){// 如果当前的元素比比较的元素值小，那么进行移动
                    array[n1+1]=array[n1];
                }else{
                    break;
                }
            }

            // 插入(这里不确定是否加1，那么可以随便找个数字来带入下得出结论)
            array[n1+1]=a;
        }
    }
```

### 适合大数据规模的排序

> 冒泡排序，插入排序这些排序算法的复杂度是O(n2)；
>
> 而快速排序和归并排序的时间复杂度是O(nlogn).

快速排序

```java
public static void main(String[] args) {
        int[] array=new int[]{1,6,3,9,0};


        quickSorted(array,0,array.length-1);

        System.out.println(Arrays.toString(array));
    }


    public static void quickSorted(int[] array,int left,int right){
        if (left>=right) return;
        int partition = partition(array, left, right);
        quickSorted(array,left,partition-1);

        quickSorted(array,partition+1,right);
    }


    public static int partition(int[] array,int left,int right){
        int point=left;
        int index=left+1;
        for (int j = index; j <= right; j++) {
            if (array[j]>array[point]){
                // 交换
                int temp=array[j];
                array[j]=array[index];
                array[index]=temp;
                index++;
            }
        }

        // 基准点与最后一个进行交换
        int temp=array[point];
        array[point]=array[index-1];
        array[index-1]=temp;

        return index-1;
    }
```

课后题

> 现在你有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并吗？

思路就是把10个文件放到最小堆里面，每次取一个最小的值放到最新的文件中。
